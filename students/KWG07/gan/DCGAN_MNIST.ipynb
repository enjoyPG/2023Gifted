{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "#set manual seed to a constant get a consistent output\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "dataset = dset.FashionMNIST(root='./data', download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize(28),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "#number of channels in image(since the image is grayscale the number of channels are 1)\n",
    "nc=1\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "Data_name=\"MNIST/\"\n",
    "\n",
    "#checking the availability of cuda devices\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# number of gpu's available\n",
    "ngpu = 1\n",
    "# input noise dimension\n",
    "nz = 100\n",
    "# number of generator filters\n",
    "ngf = 64\n",
    "#number of discriminator filters\n",
    "ndf = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu, nc=1, nz=100, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(    ngf,      nc, kernel_size=1, stride=1, padding=2, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, nc=1, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "netG.load_state_dict(torch.load('./weights/'+Data_name+'netG_epoch_99.pth'))\n",
    "print(netG)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "netD.load_state_dict(torch.load('./weights/'+Data_name+'netD_epoch_99.pth'))\n",
    "print(netD)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "niter = 0 #epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "        label = label.type(torch.FloatTensor).cuda()\n",
    "\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        output = output.type(torch.FloatTensor).cuda()\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        label.fill_(fake_label)\n",
    "        fake = netG(noise)\n",
    "        #label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label) \n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'% (epoch, niter, i, len(dataloader),errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,'./output/real_samples.png' ,normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),'./output/fake_samples_epoch_%03d.png' % (epoch), normalize=True)        \n",
    "    torch.save(netG.state_dict(), './weights/'+Data_name+'netG_epoch_%d.pth' % (epoch))\n",
    "    torch.save(netD.state_dict(), './weights/'+Data_name+'netD_epoch_%d.pth' % (epoch))\n",
    "\n",
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# load the models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(ngpu=1).eval()\n",
    "G = Generator(ngpu=1).eval()\n",
    "\n",
    "# load weights\n",
    "D.load_state_dict(torch.load('./weights/'+Data_name+'netD_epoch_99.pth'))\n",
    "G.load_state_dict(torch.load('./weights/'+Data_name+'netG_epoch_99.pth'))\n",
    "if torch.cuda.is_available():\n",
    "    D = D.cuda()\n",
    "    G = G.cuda()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "latent_size = 100\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, latent_size, 1, 1)\n",
    "if torch.cuda.is_available():\n",
    "    fixed_noise = fixed_noise.cuda()\n",
    "fake_images = G(fixed_noise)\n",
    "\n",
    "# z = torch.randn(batch_size, latent_size).cuda()\n",
    "# z = Variable(z)\n",
    "# fake_images = G(z)\n",
    "\n",
    "fake_images_np = fake_images.cpu().detach().numpy()\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 28, 28)\n",
    "R, C = 1,10\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(fake_images_np[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN 에 대한 조사로 변경\n",
    "\n",
    "GAN 정리 후 DCGAN 정리\n",
    "\n",
    "결과 보여주며 마침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
